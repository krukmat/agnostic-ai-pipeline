# Product Owner - Teacher Dataset Generation (Hybrid Strategy)
**Fecha**: 2025-11-10
**Task**: 9.D.2 - Generaci√≥n Dataset Maestro (EN CURSO)
**Status**: üöß EN PROGRESO (237/300 registros, 79.0%)
**Estrategia**: H√≠brida (45 registros `gemini-2.5-pro` + 192 registros `gemini-2.5-flash`, threshold 0.80)

---

## üìã Resumen Ejecutivo

### Problema Identificado
Durante la generaci√≥n inicial del teacher dataset con `gemini-2.5-pro`, se detect√≥ una tasa de √©xito muy baja (~20-25%) con los siguientes problemas:

- ‚ùå **80% de intentos fallaban** con "Missing VISION/REVIEW content"
- ‚ùå Modelo no generaba estructura YAML v√°lida consistentemente
- ‚ùå Tiempo estimado: **25-30 horas** para 400 registros
- ‚ùå Proceso estancado en 45 registros con m√∫ltiples horas de ejecuci√≥n

### Soluci√≥n Implementada (Estrategia H√≠brida)
**Cambio a gemini-2.5-flash con threshold reducido**:

1. ‚úÖ **Preservar registros existentes**: 45 registros de gemini-2.5-pro guardados
2. ‚úÖ **Cambiar modelo**: gemini-2.5-pro ‚Üí gemini-2.5-flash
3. ‚úÖ **Reducir threshold**: 0.85 ‚Üí 0.80 (aumenta aceptaci√≥n de muestras v√°lidas)
4. üîÑ **Target ajustado**: 300 registros (fase 1) ‚Äî objetivo actual cumplido al 79%

### Resultados Iniciales (gemini-2.5-flash)
- ‚úÖ **Tasa de √©xito mejorada**: ~40-50% (vs 20-25% anterior)
- ‚úÖ **Calidad excelente**: scores promedio ~0.89-0.95
- ‚úÖ **Retry mechanism funciona**: ~60-70% de retries son exitosos
- ‚úÖ **Tiempo estimado reducido**: **~4-5 horas** para 400 registros (vs 25-30h)

---

## üîß Implementaci√≥n T√©cnica

### Comando Anterior (FALLIDO)
```bash
# gemini-2.5-pro con threshold 0.85 (20-25% success rate)
PYTHONPATH=. .venv/bin/python scripts/generate_po_teacher_dataset.py \
  --provider vertex_sdk \
  --model gemini-2.5-pro \
  --max-records 400 \
  --min-score 0.85 \
  --seed 555 \
  --resume
```

**Resultado**: Estancado en 45 registros despu√©s de ~90 minutos

### Comando Actual (EN PROGRESO)
```bash
# gemini-2.5-flash con threshold 0.80 (40-50% success rate)
PYTHONPATH=. .venv/bin/python scripts/generate_po_teacher_dataset.py \
  --provider vertex_sdk \
  --model gemini-2.5-flash \
  --max-records 300 \
  --min-score 0.80 \
  --seed 555 \
  --resume \
  2>&1 | tee /tmp/teacher_hybrid_flash.log
```

**PID**: Se ejecuta en sesiones puntuales (√∫ltimo batch completado a las 15:08 CET)

### Archivos de Backup
- `artifacts/distillation/po_teacher_dataset_backup_45.jsonl` (220KB, 45 registros `gemini-2.5-pro`)
- `artifacts/distillation/po_teacher_dataset.jsonl` (dataset activo, 237 registros | media 0.899)

---

## üìä An√°lisis de Performance

### Comparaci√≥n de Modelos

| M√©trica | gemini-2.5-pro | gemini-2.5-flash |
|---------|----------------|------------------|
| Success Rate | 20-25% | 40-50% |
| Avg Score | 0.85-0.90 | 0.89-0.95 |
| Missing VISION/REVIEW | ~80% | ~30-40% |
| Retry Success | N/A | ~60-70% |
| Tiempo/400 registros | 25-30h | 4-5h |
| Costo estimado | Alto | Medio |

### Patr√≥n de Errores Observados

**gemini-2.5-flash (ACTUAL)**:
```
[12:54:29] ‚úÖ Stored sample #2 (score=0.910)
[12:54:42] ‚ö†Ô∏è  REVIEW block missing ‚Äî retrying with explicit instruction
[12:54:55] ‚ùå Missing VISION/REVIEW content, skipping
[12:55:07] ‚ö†Ô∏è  REVIEW block missing ‚Äî retrying with explicit instruction
[12:55:19] ‚ùå REVIEW block missing after retry
[12:55:31] ‚ö†Ô∏è  REVIEW block missing ‚Äî retrying with explicit instruction
[12:55:40] ‚úÖ Stored sample #3 (score=0.893)
[12:55:49] ‚úÖ Stored sample #4 (score=0.886)
[12:56:02] ‚ùå Missing VISION/REVIEW content, skipping
[12:56:14] ‚úÖ Stored sample #5 (score=0.910)
```

**An√°lisis**:
- **Errores manejables**: El retry mechanism funciona correctamente
- **Quality alta**: Todos los samples aceptados tienen score ‚â•0.886 (bien por encima del threshold 0.80)
- **Velocidad**: ~1.3 registros/minuto (incluyendo retries)

---

## üéØ Estado Actual

### Dataset Generado
```
Registros actuales: 237 / 300 (79.0%)
Progreso: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 79%
√öltima actualizaci√≥n: 2025-11-10 15:10 CET
```

**Calidad del Dataset**:
- Score promedio: **0.899**
- Score m√≠nimo aceptado: 0.800
- Score m√°ximo: **0.984**
- √öltimo registro: score = **0.947**

### Logs Activos
- **Generaci√≥n**: `/tmp/teacher_hybrid_flash.log`
- **Monitor**: `/tmp/monitor_teacher_dataset.sh` (checking every 5 min)
- **Pipeline**: `logs/pipeline.log`

### ETA Estimado

**Con performance actual (1.3 registros/min)**:
```
Registros restantes: 63
ETA: ~48 minutos
Finalizaci√≥n estimada: ~16:00 CET (2025-11-10)
```

---

## ‚ö†Ô∏è Issues y Observaciones

### Issue #1: REVIEW Block Generation
**Problema**: gemini-2.5-flash ocasionalmente omite el bloque REVIEW en primera respuesta

**Evidencia**:
- ~30-40% de respuestas requieren retry
- Mensaje: "REVIEW block missing ‚Äî retrying with explicit instruction"

**Impacto**: BAJO
- El retry mechanism funciona en ~60-70% de casos
- No bloquea la generaci√≥n, solo aumenta el tiempo levemente
- Calidad de los samples despu√©s del retry es comparable

**Soluci√≥n Actual**: Retry autom√°tico implementado en `scripts/generate_po_teacher_dataset.py`

**Mejoras Futuras**:
1. Ajustar prompt para ser m√°s expl√≠cito sobre estructura YAML requerida
2. Agregar ejemplos de YAML v√°lido en el prompt
3. Considerar structured output API si Vertex AI lo soporta

---

## üìù Archivos Involucrados

### Scripts
- `scripts/generate_po_teacher_dataset.py` (generaci√≥n con retry logic)
  - L√≠nea ~XX: Retry mechanism para REVIEW block
  - L√≠nea ~XX: Scoring con `product_owner_metric`

### Datasets
- `artifacts/distillation/po_teacher_dataset.jsonl` (ACTIVO, 53 registros)
- `artifacts/distillation/po_teacher_dataset_backup_45.jsonl` (backup gemini-2.5-pro)
- `artifacts/synthetic/product_owner/concepts.jsonl` (source concepts)

### Logs
- `/tmp/teacher_hybrid_flash.log` (ejecuci√≥n actual)
- `/tmp/monitor_output.log` (monitor script)
- `logs/pipeline.log` (pipeline general)

---

## üîó Contexto: Fase 9.D (Distillation Strategy)

Este trabajo es parte de la estrategia completa de distillation:

### Flujo Completo
1. ‚úÖ **Task 9.0.7**: Baseline evaluation (score: 0.831 / 83.1%)
2. ‚úÖ **Task 9.0.8**: MIPROv2 optimization + serialization fix
3. üöß **Task 9.D.2**: Teacher dataset generation (ESTA TAREA - EN CURSO)
   - **Estado**: 53/400 registros (13.25%)
   - **Modelo**: gemini-2.5-flash (Vertex AI)
   - **Target**: 400 registros con score ‚â•0.80
   - **ETA**: ~4.5 horas
4. ‚è≠Ô∏è **Task 9.D.3**: Fine-tuning LoRA student model
   - Base: mistral-7b-instruct
   - Dataset: Teacher dataset (400 ejemplos alta calidad)
   - T√©cnica: LoRA (rank 32, alpha 64)
   - Plataforma: Google Colab (FREE o Pro)
5. ‚è≠Ô∏è **Task 9.D.4**: Validaci√≥n modelo distillado
6. ‚è≠Ô∏è **Task 9.D.5**: Integraci√≥n al pipeline

### Objetivo Final (Fase 9.D)
Reemplazar modelo teacher lento (gemini-2.5-flash/pro) con modelo local distillado, habilitando:
- MIPROv2 repetible y r√°pido (~10x faster)
- Reducci√≥n de costos (sin API calls para inferencia)
- Experimentaci√≥n √°gil con product owner optimization

---

## üìÖ Pr√≥ximos Pasos

### Inmediatos (Task 9.D.2 - EN CURSO)

**1. Monitorear Generaci√≥n Actual** ‚è∞
- **Acci√≥n**: Esperar a que el proceso complete 400 registros
- **Verificaci√≥n**: Revisar `/tmp/teacher_hybrid_flash.log` cada hora
- **Comando**:
  ```bash
  wc -l artifacts/distillation/po_teacher_dataset.jsonl
  tail -20 /tmp/teacher_hybrid_flash.log
  ```
- **Criterio de √©xito**: 400 registros con score promedio ‚â•0.85

**2. An√°lisis de Calidad del Dataset** üìä
- **Cuando**: Al alcanzar 400 registros
- **Acciones**:
  ```bash
  # An√°lisis estad√≠stico
  python3 -c "
  import json
  scores = []
  with open('artifacts/distillation/po_teacher_dataset.jsonl') as f:
      for line in f:
          scores.append(json.loads(line)['score'])

  print(f'Total: {len(scores)}')
  print(f'Mean: {sum(scores)/len(scores):.3f}')
  print(f'Min: {min(scores):.3f}')
  print(f'Max: {max(scores):.3f}')
  print(f'Median: {sorted(scores)[len(scores)//2]:.3f}')
  "
  ```

**3. Preparar Training Pipeline** üõ†Ô∏è
- **Cuando**: Dataset completo (400 registros)
- **Acciones**:
  1. Crear script de training: `scripts/train_po_student.py`
     - Basado en Hugging Face Transformers + PEFT
     - LoRA config: rank=32, alpha=64, target_modules=['q_proj', 'v_proj']
     - Optimizaci√≥n: AdamW con learning rate 2e-4

  2. Crear Colab notebook template: `notebooks/po_student_training.ipynb`
     - Setup de GPU (T4/V100)
     - Instalaci√≥n de dependencias
     - Training loop con validaci√≥n
     - Export de modelo fine-tuned

  3. Split dataset (train/val):
     ```bash
     python3 scripts/split_teacher_dataset.py \
       --input artifacts/distillation/po_teacher_dataset.jsonl \
       --train artifacts/distillation/po_train.jsonl \
       --val artifacts/distillation/po_val.jsonl \
       --split 0.85
     ```

### Siguientes (Task 9.D.3 - Fine-tuning)

**4. Ejecutar Fine-tuning en Colab** üéì
- **Plataforma**: Google Colab (FREE tier con T4 GPU)
- **Duraci√≥n estimada**: 2-4 horas
- **Recursos necesarios**:
  - GPU: T4 (15GB VRAM) - suficiente con LoRA
  - RAM: 12GB
  - Disk: 10GB
- **Comando**:
  ```bash
  # En Colab
  !python scripts/train_po_student.py \
    --base_model mistralai/Mistral-7B-Instruct-v0.2 \
    --train_data artifacts/distillation/po_train.jsonl \
    --val_data artifacts/distillation/po_val.jsonl \
    --output_dir artifacts/models/po_student_lora \
    --lora_r 32 \
    --lora_alpha 64 \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 2e-4
  ```

**5. Validar Modelo Distillado** ‚úÖ
- **Cuando**: Training completo
- **M√©tricas**:
  - Score en validation set (target: ‚â•0.75)
  - Comparaci√≥n con teacher model (gap <10%)
  - Tiempo de inferencia (target: <10s por sample)
- **Comando**:
  ```bash
  python scripts/evaluate_po_student.py \
    --model artifacts/models/po_student_lora \
    --valset artifacts/synthetic/product_owner/product_owner_val.jsonl \
    --output artifacts/evaluation/po_student_eval.json
  ```

**6. Integrar al Pipeline** üîÑ
- **Acciones**:
  1. Crear Modelfile para Ollama:
     ```bash
     # Exportar a GGUF
     python scripts/export_to_gguf.py \
       --model artifacts/models/po_student_lora \
       --output artifacts/models/po_student.gguf

     # Importar a Ollama
     ollama create po-student -f Modelfile
     ```

  2. Actualizar `config.yaml`:
     ```yaml
     roles:
       product_owner:
         provider: ollama
         model: po-student
     ```

  3. Re-run baseline evaluation con modelo student
  4. Comparar performance vs teacher model

### Opcionales (Mejoras)

**7. Fix Issue #1 (REVIEW Block Generation)** üîß
- **Acci√≥n**: Mejorar prompt en `scripts/generate_po_teacher_dataset.py`
- **Estrategia**:
  1. Agregar ejemplo de YAML v√°lido
  2. Hacer instrucci√≥n m√°s expl√≠cita sobre bloques requeridos
  3. Considerar few-shot prompting
- **Prioridad**: BAJA (retry mechanism funciona)

**8. An√°lisis Comparativo (gemini-2.5-pro vs flash)** üìà
- **Acci√≥n**: Comparar calidad de registros por modelo
- **An√°lisis**:
  ```bash
  # Primeros 45 registros (gemini-2.5-pro)
  head -45 artifacts/distillation/po_teacher_dataset.jsonl | \
    python3 -c "import sys, json; scores=[json.loads(l)['score'] for l in sys.stdin]; print(f'Mean: {sum(scores)/len(scores):.3f}')"

  # Registros 46+ (gemini-2.5-flash)
  tail -n +46 artifacts/distillation/po_teacher_dataset.jsonl | \
    python3 -c "import sys, json; scores=[json.loads(l)['score'] for l in sys.stdin]; print(f'Mean: {sum(scores)/len(scores):.3f}')"
  ```

---

## üéì Lessons Learned

### 1. Model Selection para Structured Output
**Observaci√≥n**: gemini-2.5-flash es **m√°s confiable** que gemini-2.5-pro para generaci√≥n de structured YAML

**Razones posibles**:
- gemini-2.5-flash optimizado para tasks m√°s simples (mejor instruction following)
- gemini-2.5-pro puede "sobre-pensar" y desviar de formato estricto
- Flash tiene mejor ratio costo/performance para este use case

**Recomendaci√≥n**: Para tareas de structured output, probar modelos "flash" antes que "pro"

### 2. Importance of Retry Mechanisms
**Observaci√≥n**: El retry mechanism con instrucci√≥n expl√≠cita rescata ~60-70% de intentos fallidos

**Implementaci√≥n**:
```python
# Primera intenci√≥n
response = model.generate(prompt)

# Si falta bloque REVIEW
if "REVIEW:" not in response:
    retry_prompt = prompt + "\n\nIMPORTANT: You MUST include a REVIEW block with the structure:\nREVIEW:\n  completeness: X\n  ..."
    response = model.generate(retry_prompt)
```

**Recomendaci√≥n**: Siempre implementar retry logic para structured output tasks

### 3. Threshold Tuning
**Observaci√≥n**: Reducir threshold de 0.85 ‚Üí 0.80 aument√≥ acceptance rate sin sacrificar calidad significativa

**Datos**:
- Con threshold 0.85: ~45 registros aceptados de ~200+ intentos (22.5%)
- Con threshold 0.80: Score promedio de aceptados = 0.90 (bien por encima del threshold)

**Recomendaci√≥n**: Usar threshold conservador inicialmente, luego ajustar basado en distribuci√≥n real de scores

---

## üìö Referencias

- **Plan Maestro**: `docs/fase9_multi_role_dspy_plan.md:616-757` (Fase 9.D)
- **Schema PO**: `docs/fase9_product_owner_schema.md`
- **Baseline Evaluation**: Task 9.0.7 (score: 0.831)
- **MIPROv2 Optimization**: `docs/PO_MIPRO_OPTIMIZATION_REPORT.md`
- **Vertex AI Docs**: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini
- **LoRA Paper**: https://arxiv.org/abs/2106.09685
- **Colab Setup**: https://colab.research.google.com/

---

## üìû Comandos de Monitoreo

### Check Progress
```bash
# Ver cantidad de registros
wc -l artifacts/distillation/po_teacher_dataset.jsonl

# Ver √∫ltimos scores
tail -10 artifacts/distillation/po_teacher_dataset.jsonl | \
  python3 -c "import sys, json; [print(f\"Score: {json.loads(l)['score']:.3f}\") for l in sys.stdin]"

# Ver log en tiempo real
tail -f /tmp/teacher_hybrid_flash.log
```

### Verify Process
```bash
# Check si el proceso est√° corriendo
ps aux | grep generate_po_teacher_dataset.py

# Ver √∫ltimas 50 l√≠neas del log
tail -50 /tmp/teacher_hybrid_flash.log

# Filtrar solo samples exitosos
grep "Stored sample" /tmp/teacher_hybrid_flash.log | tail -20
```

### Stop/Restart Process
```bash
# Detener proceso actual
pkill -f "generate_po_teacher_dataset.py"

# Reiniciar con resume
PYTHONPATH=. .venv/bin/python scripts/generate_po_teacher_dataset.py \
  --provider vertex_sdk \
  --model gemini-2.5-flash \
  --max-records 400 \
  --min-score 0.80 \
  --seed 555 \
  --resume \
  2>&1 | tee /tmp/teacher_hybrid_flash.log
```

---

**√öltima actualizaci√≥n**: 2025-11-10 13:00 CET
**Pr√≥xima revisi√≥n**: Al completar 150 registros (ETA: ~14:00 CET)
