# Fase 8.4: Fine-Tuning en CPU - Gu√≠a de Continuidad

**Fecha Creaci√≥n**: 2025-11-09
**Decisi√≥n**: Opci√≥n C - CPU con bf16 (100% local, sin GPU)
**Tiempo Estimado**: 73+ horas (3 d√≠as continuos)
**Objetivo**: Fine-tuning de Mistral-7B-Instruct con LoRA en CPU para mejorar score BA de 85.35% ‚Üí 90%+

---

## Estado Actual (2025-11-09 16:54)
- ‚úÖ Checklist previo completado (modelo local, datasets corregidos, dependencias).
- ‚úÖ Comando lanzado en background con `nohup`:
  ```
  nohup .venv/bin/python scripts/finetune_ba.py ... --quantization bf16 > /tmp/finetune_ba_cpu_bf16.log 2>&1 &
  echo $! > /tmp/finetune_ba_pid.txt
  ```
- üóÇÔ∏è Output: `artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16`
- üßæ Log: `/tmp/finetune_ba_cpu_bf16.log`
- üî¢ PID: `$(cat /tmp/finetune_ba_pid.txt)` (consultar antes de cerrar terminales)
- üìå Pr√≥ximo hito: dejar correr ~73 h y luego continuar con evaluaci√≥n 3-way.

---

## ‚ö†Ô∏è ADVERTENCIA CR√çTICA

Este proceso tomar√° aproximadamente **73 horas (3 d√≠as)** de ejecuci√≥n continua en CPU.

**Limitaciones conocidas**:
- ‚ùå NO usa cuantizaci√≥n 4-bit (bitsandbytes CPU-only no soporta)
- ‚ùå Modelo completo en RAM (~13GB en bf16)
- ‚è±Ô∏è ~15 min por batch step (1 ejemplo)
- ‚è±Ô∏è ~98 steps/√©poca √ó 3 √©pocas = 294 steps √ó 15 min = **73.5 horas**

**Trade-offs aceptados**:
- ‚úÖ 100% CPU local, $0 costo
- ‚úÖ No requiere GPU ni cloud
- ‚úÖ Cumple objetivo Fase 8 (pipeline local)
- ‚ùå No escalable a otros roles sin optimizaci√≥n

---

## üìã CHECKLIST PRE-EJECUCI√ìN

Antes de iniciar el fine-tuning, verificar:

### 1. Espacio en Disco
```bash
# Verificar espacio disponible (necesario: ~30GB)
df -h /Users/matiasleandrokruk/Documents/agnostic-ai-pipeline

# Breakdown:
# - Modelo Mistral-7B: ~13GB (artifacts/models/mistral-7b-instruct/)
# - Checkpoints: ~2GB por checkpoint √ó 2 = 4GB
# - Logs: ~500MB
# - LoRA adapters: ~50MB
# - Total: ~18GB + margen ‚Üí 30GB recomendado
```

### 2. RAM Disponible
```bash
# Verificar RAM (necesario: 16GB m√≠nimo, 32GB recomendado)
# macOS:
vm_stat | perl -ne '/page size of (\d+)/ and $size=$1; /Pages\s+([^:]+)[^\d]+(\d+)/ and printf("%-16s % 16.2f Mi\n", "$1:", $2 * $size / 1048576);'

# Cerrar aplicaciones pesadas antes de iniciar
# - Chrome/Firefox (usar Safari si es necesario)
# - Docker Desktop
# - IDEs (VSCode, IntelliJ)
# - Aplicaciones de virtualizaci√≥n
```

### 3. Datasets Corregidos
```bash
# Verificar datasets existen y tienen formato correcto
ls -lh artifacts/synthetic/ba_train_v2_fixed.jsonl
ls -lh artifacts/synthetic/ba_val_v2_fixed.jsonl

# Verificar cantidad de ejemplos
wc -l artifacts/synthetic/ba_train_v2_fixed.jsonl  # Debe ser 98
wc -l artifacts/synthetic/ba_val_v2_fixed.jsonl    # Debe ser 22

# Validar formato JSONL (una l√≠nea = error)
head -n 1 artifacts/synthetic/ba_train_v2_fixed.jsonl | python3 -m json.tool > /dev/null && echo "‚úÖ JSON v√°lido" || echo "‚ùå JSON inv√°lido"
```

### 4. Dependencias Instaladas
```bash
# Verificar librer√≠as Python
.venv/bin/python -c "
import transformers
import peft
import bitsandbytes
import accelerate
import datasets
import torch
import typer
import yaml
print('‚úÖ Todas las dependencias OK')
print(f'transformers: {transformers.__version__}')
print(f'peft: {peft.__version__}')
print(f'torch: {torch.__version__}')
"

# Versiones esperadas:
# - transformers: 4.48.3
# - peft: 0.17.1
# - bitsandbytes: 0.42.0 (CPU-only, warning esperado)
# - accelerate: 0.34.2
# - datasets: 3.6.0
# - torch: 2.9.0
```

### 5. Modelo Base Descargado
```bash
# Verificar si modelo existe localmente
ls -lh artifacts/models/mistral-7b-instruct/

# Si NO existe, descargarlo ANTES de ejecutar fine-tuning:
# (Requiere huggingface-cli instalado y conexi√≥n a internet)
huggingface-cli download mistralai/Mistral-7B-Instruct-v0.1 \
  --local-dir artifacts/models/mistral-7b-instruct \
  --local-dir-use-symlinks False

# Verificar tama√±o (~13GB)
du -sh artifacts/models/mistral-7b-instruct
```

### 6. Script Fine-Tuning Existe
```bash
# Verificar script
ls -lh scripts/finetune_ba.py

# Probar CLI help (sin ejecutar training)
.venv/bin/python scripts/finetune_ba.py --help
```

---

## üöÄ EJECUCI√ìN PASO A PASO

### PASO 1: Preparar Entorno de Ejecuci√≥n

**1.1. Crear directorio de output**
```bash
mkdir -p artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16
```

**1.2. Crear archivo de log de ejecuci√≥n**
```bash
# Preparar archivo de monitoreo
touch /tmp/finetune_ba_cpu_bf16.log
```

**1.3. Configurar variables de entorno (opcional)**
```bash
# Deshabilitar TensorBoard si da problemas
export WANDB_DISABLED=true
export TOKENIZERS_PARALLELISM=false
```

---

### PASO 2: Comando de Fine-Tuning

**Comando COMPLETO para ejecutar**:

```bash
cd /Users/matiasleandrokruk/Documents/agnostic-ai-pipeline

nohup .venv/bin/python scripts/finetune_ba.py \
  --train artifacts/synthetic/ba_train_v2_fixed.jsonl \
  --val artifacts/synthetic/ba_val_v2_fixed.jsonl \
  --output artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16 \
  --base-model artifacts/models/mistral-7b-instruct \
  --epochs 3 \
  --lr 2e-4 \
  --batch-size 1 \
  --grad-accum 8 \
  --lora-r 8 \
  --lora-alpha 32 \
  --lora-dropout 0.1 \
  --max-length 2048 \
  --seed 42 \
  --quantization bf16 \
  > /tmp/finetune_ba_cpu_bf16.log 2>&1 &

# Guardar PID del proceso
echo $! > /tmp/finetune_ba_pid.txt

echo "‚úÖ Fine-tuning iniciado en background"
echo "üìÑ Logs: /tmp/finetune_ba_cpu_bf16.log"
echo "üî¢ PID: $(cat /tmp/finetune_ba_pid.txt)"
```

**Nota**: `nohup` + `&` permite que el proceso contin√∫e aunque cierres la terminal.

---

### PASO 3: Monitoreo Durante Ejecuci√≥n

#### 3.1. Ver Logs en Tiempo Real
```bash
# Ver √∫ltimas 100 l√≠neas actualizadas cada 5 segundos
tail -f -n 100 /tmp/finetune_ba_cpu_bf16.log
```

#### 3.2. Verificar Proceso Activo
```bash
# Ver si el proceso sigue corriendo
ps aux | grep finetune_ba.py

# O usando el PID guardado
ps -p $(cat /tmp/finetune_ba_pid.txt)
```

#### 3.3. Monitorear Uso de RAM
```bash
# Cada 30 segundos, ver RAM usada por el proceso
watch -n 30 "ps aux | grep finetune_ba.py | grep -v grep | awk '{print \$4, \$11}'"
```

#### 3.4. Checkpoints Guardados
```bash
# Ver checkpoints generados (uno por √©poca)
ls -lh artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/checkpoint-*

# Ver contenido de checkpoints
ls artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/checkpoint-*/
```

#### 3.5. Timeline Esperado

**Hitos clave a monitorear** (basado en logs):

| Tiempo (aprox) | Hito | Log esperado |
|----------------|------|--------------|
| T+0:00 | Inicio | `FASE 8.4: Fine-Tuning LoRA - Mistral-7B-Instruct` |
| T+0:05 | Tokenizer cargado | `Loading tokenizer from ...` |
| T+0:10 | Modelo cargado | `Loading model ... with 4-bit quantization` (fallback bf16) |
| T+0:11 | LoRA aplicado | `Applying LoRA configuration (r=8, alpha=32)...` |
| T+0:12 | Datasets tokenizados | `Tokenizing datasets...` |
| T+0:15 | Training inicia | `Starting training...` |
| T+24:30 | √âpoca 1/3 completa | `Epoch 1/3: 100%` (98 steps √ó 15 min = 1,470 min = 24.5h) |
| T+24:33 | Evaluaci√≥n √âpoca 1 | `Evaluating: 100%` (22 examples) |
| T+49:03 | √âpoca 2/3 completa | `Epoch 2/3: 100%` |
| T+49:06 | Evaluaci√≥n √âpoca 2 | `Evaluating: 100%` |
| T+73:33 | √âpoca 3/3 completa | `Epoch 3/3: 100%` |
| T+73:36 | Evaluaci√≥n √âpoca 3 | `Evaluating: 100%` |
| T+73:37 | Guardado adapters | `Saving LoRA adapters to ...` |
| T+73:38 | COMPLETADO | `‚úÖ Fine-tuning completed!` |

**Total estimado**: **~73.5 horas (3 d√≠as, 1.5 horas)**

---

## üîß MANEJO DE INTERRUPCIONES

### Si el Proceso se Interrumpe

#### 1. Verificar Estado
```bash
# Ver si el proceso sigue activo
ps -p $(cat /tmp/finetune_ba_pid.txt) && echo "‚úÖ Proceso activo" || echo "‚ùå Proceso detenido"

# Ver √∫ltimos logs
tail -n 50 /tmp/finetune_ba_cpu_bf16.log
```

#### 2. Identificar √öltima √âpoca Completada
```bash
# Ver checkpoints guardados
ls -lhrt artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/checkpoint-*/

# Ejemplo:
# checkpoint-98/   ‚Üí √âpoca 1 completa
# checkpoint-196/  ‚Üí √âpoca 2 completa
```

#### 3. Reiniciar desde Checkpoint (SI es posible)

**Opci√≥n A: HuggingFace Trainer resume autom√°tico**
```bash
# El Trainer detecta checkpoints y puede resumir
# Re-ejecutar el mismo comando original
# NOTA: Esto funciona si la interrupci√≥n fue limpia (ej. SIGTERM)

nohup .venv/bin/python scripts/finetune_ba.py \
  --train artifacts/synthetic/ba_train_v2_fixed.jsonl \
  --val artifacts/synthetic/ba_val_v2_fixed.jsonl \
  --output artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16 \
  --base-model artifacts/models/mistral-7b-instruct \
  --epochs 3 \
  --lr 2e-4 \
  --batch-size 1 \
  --grad-accum 8 \
  --lora-r 8 \
  --lora-alpha 32 \
  --lora-dropout 0.1 \
  --max-length 2048 \
  --seed 42 \
  --quantization bf16 \
  > /tmp/finetune_ba_cpu_bf16_resume.log 2>&1 &
```

**Opci√≥n B: Usar checkpoint como modelo base (SI solo falta 1 √©poca)**
```bash
# Si checkpoint-196 existe (2 √©pocas completadas), entrenar 1 √©poca m√°s
# NOTA: Esto requiere modificar el script para soportar `--resume-from-checkpoint`
# Por ahora, reiniciar desde el principio es m√°s seguro
```

#### 4. Si Reinicio Completo es Necesario
```bash
# Limpiar output directory
rm -rf artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/*

# Re-ejecutar comando original
# (ver PASO 2)
```

---

## üìä POST-EJECUCI√ìN: VERIFICACI√ìN

### 1. Verificar Finalizaci√≥n Exitosa
```bash
# Buscar mensaje de √©xito en logs
grep "Fine-tuning completed" /tmp/finetune_ba_cpu_bf16.log

# Ver √∫ltimas l√≠neas del log
tail -n 100 /tmp/finetune_ba_cpu_bf16.log
```

### 2. Verificar Artefactos Generados
```bash
# Estructura esperada:
ls -lhR artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/

# Archivos cr√≠ticos:
# ‚îú‚îÄ‚îÄ adapter_config.json          # Configuraci√≥n LoRA
# ‚îú‚îÄ‚îÄ adapter_model.bin             # Weights LoRA (~50MB)
# ‚îú‚îÄ‚îÄ tokenizer_config.json         # Tokenizer config
# ‚îú‚îÄ‚îÄ tokenizer.json                # Tokenizer
# ‚îú‚îÄ‚îÄ special_tokens_map.json       # Special tokens
# ‚îú‚îÄ‚îÄ training_info.json            # Metadatos
# ‚îî‚îÄ‚îÄ logs/                         # TensorBoard logs

# Verificar tama√±o de adapter_model.bin (~50-80MB esperado)
ls -lh artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/adapter_model.bin
```

### 3. Revisar Metadatos de Training
```bash
# Ver training_info.json
cat artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/training_info.json | python3 -m json.tool

# Campos clave a verificar:
# - "epochs": 3
# - "train_examples": 98
# - "val_examples": 22
# - "trainable_params": ~4M (0.05% del total)
```

---

## üìà SIGUIENTE FASE: EVALUACI√ìN

Una vez completado el fine-tuning exitosamente:

### Fase 8.5: Evaluaci√≥n 3-Way Comparison

**Objetivo**: Comparar 3 modelos:
1. **M1 Baseline**: mistral:7b-instruct (sin optimizaci√≥n) - 72%
2. **M2 Optimized**: mistral:7b-instruct + MIPROv2 - **85.35%**
3. **M3 Fine-Tuned**: mistral:7b-instruct + LoRA - **TBD**

**Script a ejecutar**:
```bash
# Ver protocolo completo en:
cat docs/fase8_evaluation_strategy.md

# Comando de evaluaci√≥n (a implementar):
.venv/bin/python scripts/compare_ba_models.py \
  --baseline "ollama:mistral:7b-instruct" \
  --optimized "artifacts/dspy/local_base_optimized" \
  --finetuned "artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16" \
  --dataset artifacts/synthetic/ba_val_v2_fixed.jsonl \
  --output artifacts/fase8/3way_comparison.json
```

**Criterios de Decisi√≥n**:
- ‚úÖ **Si M3 ‚â• 90% Y mejora +5% sobre M2** ‚Üí Adoptar fine-tuned
- ‚ö†Ô∏è **Si M3 mejora <5%** ‚Üí Mantener M2 (simplicidad)
- ‚ùå **Si M3 < M2** ‚Üí Mantener M2 (overfitting detectado)

---

## üóÇÔ∏è ARCHIVOS DE REFERENCIA

| Documento | Ubicaci√≥n | Contenido |
|-----------|-----------|-----------|
| **Plan Fine-Tuning** | `docs/fase8_finetuning_plan.md` | Config LoRA, hyperpar√°metros, timeline |
| **Estrategia Evaluaci√≥n** | `docs/fase8_evaluation_strategy.md` | Protocolo 3-way, m√©tricas |
| **Progreso Fase 8** | `docs/fase8_progress.md` | Historial completo tareas |
| **Continuidad** | `docs/fase8_cpu_finetuning_continuity.md` | Este documento |
| **Script Fine-Tuning** | `scripts/finetune_ba.py` | Implementaci√≥n LoRA |

---

## ‚ö° COMANDOS R√ÅPIDOS DE REFERENCIA

```bash
# ===== INICIO =====
# 1. Verificar prerequisites
.venv/bin/python -c "import transformers, peft; print('OK')"
ls -lh artifacts/synthetic/ba_*_v2_fixed.jsonl
ls -lh artifacts/models/mistral-7b-instruct/

# 2. Iniciar fine-tuning en background
cd /Users/matiasleandrokruk/Documents/agnostic-ai-pipeline
nohup .venv/bin/python scripts/finetune_ba.py \
  --train artifacts/synthetic/ba_train_v2_fixed.jsonl \
  --val artifacts/synthetic/ba_val_v2_fixed.jsonl \
  --output artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16 \
  --base-model artifacts/models/mistral-7b-instruct \
  --quantization bf16 \
  > /tmp/finetune_ba_cpu_bf16.log 2>&1 &
echo $! > /tmp/finetune_ba_pid.txt

# ===== MONITOREO =====
# Ver logs en vivo
tail -f /tmp/finetune_ba_cpu_bf16.log

# Ver proceso activo
ps -p $(cat /tmp/finetune_ba_pid.txt)

# Ver checkpoints guardados
ls -lhrt artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/checkpoint-*/

# ===== POST-EJECUCI√ìN =====
# Verificar √©xito
grep "Fine-tuning completed" /tmp/finetune_ba_cpu_bf16.log

# Ver artefactos
ls -lh artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/

# Ver metadatos
cat artifacts/finetuning/mistral-7b-ba-lora-cpu-bf16/training_info.json
```

---

## üö® SOLUCI√ìN DE PROBLEMAS

### Problema 1: Out of Memory (OOM)
**S√≠ntoma**: Proceso termina con `Killed` o `MemoryError`

**Soluci√≥n**:
1. Verificar RAM disponible: `vm_stat`
2. Cerrar aplicaciones pesadas
3. Reducir `--batch-size` a 1 (ya est√° en m√≠nimo)
4. Reducir `--max-length` a 1024 (vs 2048)
5. **√öltima opci√≥n**: Usar modelo m√°s peque√±o (3B en lugar de 7B)

### Problema 2: Proceso Muy Lento (>20 min/step)
**S√≠ntoma**: Steps demoran >20 min cada uno

**Soluci√≥n**:
1. Verificar no hay otros procesos pesados: `top`
2. Verificar temperatura CPU: si est√° throttling, puede afectar
3. **Aceptar**: 15-20 min/step es esperado en CPU
4. **Alternativa**: Considerar cloud GPU (Google Colab, AWS)

### Problema 3: Checkpoints No Se Guardan
**S√≠ntoma**: No aparecen `checkpoint-*/` despu√©s de varias horas

**Soluci√≥n**:
1. Verificar espacio en disco: `df -h`
2. Ver logs por errores de permisos
3. Verificar config: `save_strategy="epoch"` est√° en el script

### Problema 4: Modelo No Descarga (Sin Red)
**S√≠ntoma**: `socket.gaierror` o `URLError`

**Soluci√≥n**:
1. Descargar en m√°quina con red:
   ```bash
   huggingface-cli download mistralai/Mistral-7B-Instruct-v0.1 \
     --local-dir ~/mistral-7b-instruct \
     --local-dir-use-symlinks False
   ```
2. Copiar a repo:
   ```bash
   rsync -avh ~/mistral-7b-instruct/ \
     /Users/matiasleandrokruk/Documents/agnostic-ai-pipeline/artifacts/models/mistral-7b-instruct/
   ```
3. Re-ejecutar con `--base-model artifacts/models/mistral-7b-instruct`

---

## üìû CONTACTO Y CONTINUACI√ìN

Si este proceso se interrumpe y necesitas continuar:

1. **Leer este documento completo** (estimado: 10 min)
2. **Verificar estado actual**: Ver secci√≥n "MANEJO DE INTERRUPCIONES"
3. **Revisar logs**: `/tmp/finetune_ba_cpu_bf16.log`
4. **Consultar referencias**: `docs/fase8_finetuning_plan.md`
5. **Reiniciar si es necesario**: Comando en secci√≥n "PASO 2"

**Todo est√° documentado para continuidad sin p√©rdida de contexto.**

---

**√öltima Actualizaci√≥n**: 2025-11-09 (antes de iniciar fine-tuning)
**Responsable**: Sistema automatizado Fase 8
**Status**: ‚è≥ LISTO PARA EJECUTAR
