providers:
  ollama:
    type: ollama
    base_url: http://localhost:11434
  openai:
    type: openai
roles:
  ba:
    provider: ollama
    model: granite4:latest
    temperature: 0.4
    max_tokens: 8192
    top_p: 0.95
  architect:
    provider: ollama
    model: qwen2.5-coder:7b
    temperature: 0.2
    max_tokens: 4096
    top_p: 0.95
  dev:
    provider: ollama
    model: mistral:7b-instruct
    temperature: 0.2
    max_tokens: 2048
    top_p: 0.95
  qa:
    provider: ollama
    model: qwen2.5-coder:7b
    temperature: 0.2
    max_tokens: 2048
    top_p: 0.95
